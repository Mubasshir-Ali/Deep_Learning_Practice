{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Optimizing_The_Text_Generation_Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOb2sM35uvKL4UuInXRyueJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mubasshir-Ali/Deep_Learning_Practice/blob/master/NLP_Optimizing_The_Text_Generation_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3ERrflIKftm",
        "colab_type": "text"
      },
      "source": [
        "# Optimizing The Text Generation Model\n",
        "\n",
        "You've already done some amazing work with generating new songs, but so far we've seen some issues with repetition and a fair amount of incoherence. By using more data and further tweaking the model, you'll be able to get improved results. We'll once again use the Kaggle Song Lyrics Dataset here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqwTspYCKlMP",
        "colab_type": "text"
      },
      "source": [
        "# Import TensorFlow And Related Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msmo72FeKUNU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Other imports for processing data\n",
        "import string\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5olWgJNP5wVB",
        "colab_type": "text"
      },
      "source": [
        "# Get The Dataset\n",
        "As noted above, we'll utilize the Song Lyrics dataset on Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06U5Fnrp5nGC",
        "colab_type": "code",
        "outputId": "ae9a21a7-a25e-4f47-e8bf-1f72f3a85704",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 \\\n",
        "    -O /tmp/songdata.csv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-09 06:55:56--  https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.130.138, 74.125.130.101, 74.125.130.100, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.130.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/9j45bhnscmg0m14olcjdkbtm6uf6ncp1/1589007300000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-05-09 06:55:59--  https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/9j45bhnscmg0m14olcjdkbtm6uf6ncp1/1589007300000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
            "Resolving doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)... 74.125.200.132, 2404:6800:4003:c00::84\n",
            "Connecting to doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)|74.125.200.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/csv]\n",
            "Saving to: ‘/tmp/songdata.csv’\n",
            "\n",
            "/tmp/songdata.csv       [  <=>               ]  69.08M   109MB/s    in 0.6s    \n",
            "\n",
            "2020-05-09 06:56:00 (109 MB/s) - ‘/tmp/songdata.csv’ saved [72436445]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLF5buDh6FIp",
        "colab_type": "text"
      },
      "source": [
        "# First 250 Songs\n",
        "Now we've seen a model trained on just a small sample of songs, and how this often leads to repetition as you get further along in trying to generate new text. Let's switch to using the 250 songs instead, and see if our output improves. This will actually be nearly 10K lines of lyrics, which should be sufficient.\n",
        "\n",
        "Note that we won't use the full dataset here as it will take up quite a bit of RAM and processing time, but you're welcome to try doing so on your own later. If interested, you'll likely want to use only some of the more common words for the Tokenizer, which will help shrink processing time and memory needed (or else you'd have an output array hundreds of thousands of words long)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPIQiXjd6PAd",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB1IUa3T6ESX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_corpus(corpus, num_words=-1):\n",
        "  # Fit a Tokenizer on the corpus\n",
        "  if num_words > -1:\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  return tokenizer\n",
        "\n",
        "def create_lyrics_corpus(dataset, field):\n",
        "  # Remove all other punctuation\n",
        "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
        "  # Make it lowercase\n",
        "  dataset[field] = dataset[field].str.lower()\n",
        "  # Make it one long string to split by line\n",
        "  lyrics = dataset[field].str.cat()\n",
        "  corpus = lyrics.split('\\n')\n",
        "  # Remove any trailing whitespace\n",
        "  for l in range(len(corpus)):\n",
        "    corpus[l] = corpus[l].rstrip()\n",
        "  # Remove any empty lines\n",
        "  corpus = [l for l in corpus if l != '']\n",
        "\n",
        "  return corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pEEJPmf8CjO",
        "colab_type": "code",
        "outputId": "185815a9-eaec-42cb-cc7a-2011c49f6ca3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def tokenize_corpus(corpus, num_words=-1):\n",
        "  # Fit a Tokenizer on the corpus\n",
        "  if num_words > -1:\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  return tokenizer\n",
        "\n",
        "# Read the dataset from csv - this time with 250 songs\n",
        "dataset = pd.read_csv('/tmp/songdata.csv', dtype=str)[:250]\n",
        "# Create the corpus using the 'text' column containing lyrics\n",
        "corpus = create_lyrics_corpus(dataset, 'text')\n",
        "# Tokenize the corpus\n",
        "tokenizer = tokenize_corpus(corpus, num_words=2000)\n",
        "total_words = tokenizer.num_words\n",
        "\n",
        "# There should be a lot more words now\n",
        "print(total_words)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W15o1B8I-Isy",
        "colab_type": "text"
      },
      "source": [
        "# Create Sequences and Labels\n",
        "After preprocessing, we next need to create sequences and labels. Creating the sequences themselves is similar to before with texts_to_sequences, but also including the use of N-Grams; creating the labels will now utilize those sequences as well as utilize one-hot encoding over all potential output words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJAAIUaP8yg_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tsequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences for equal input length \n",
        "max_sequence_len = max([len(seq) for seq in sequences])\n",
        "sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# Split sequences between the \"input\" sequence and \"output\" predicted word\n",
        "input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n",
        "# One-hot encode the labels\n",
        "one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJVmoZG0_6-p",
        "colab_type": "code",
        "outputId": "40a8f577-fefd-4d14-839c-49cb68279e84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "# Check out how some of our data is being stored\n",
        "# The Tokenizer has just a single index per word\n",
        "print(tokenizer.word_index['know'])\n",
        "print(tokenizer.word_index['feeling'])\n",
        "# Input sequences will have multiple indexes\n",
        "print(input_sequences[5])\n",
        "print(input_sequences[6])\n",
        "# And the one hot labels will be as long as the full spread of tokenized words\n",
        "print(one_hot_labels[5])\n",
        "print(one_hot_labels[6])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31\n",
            "158\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0 111  66  86 206  29\n",
            "   4]\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0  111   66\n",
            "   86  206   29    4 1196]\n",
            "[0. 0. 0. ... 0. 0. 0.]\n",
            "[0. 0. 0. ... 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7JXFUNHA3XX",
        "colab_type": "text"
      },
      "source": [
        "# Train A (Better) Text Generation Model\n",
        "With more data, we'll cut off after 100 epochs to avoid keeping you here all day. You'll also want to change your runtime type to GPU if you haven't already (you'll need to re-run the above cells if you change runtimes)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8RPIwAyA1Ji",
        "colab_type": "code",
        "outputId": "18b50213-2bef-4915-9858-80b8be700345",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(20)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(input_sequences, one_hot_labels, epochs=100, verbose=1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 5.9860 - accuracy: 0.0462\n",
            "Epoch 2/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 5.6738 - accuracy: 0.0523\n",
            "Epoch 3/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 5.4550 - accuracy: 0.0742\n",
            "Epoch 4/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 5.2717 - accuracy: 0.1027\n",
            "Epoch 5/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 5.1095 - accuracy: 0.1251\n",
            "Epoch 6/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 4.9665 - accuracy: 0.1369\n",
            "Epoch 7/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 4.8071 - accuracy: 0.1493\n",
            "Epoch 8/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 4.6433 - accuracy: 0.1641\n",
            "Epoch 9/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 4.4955 - accuracy: 0.1794\n",
            "Epoch 10/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 4.3686 - accuracy: 0.1901\n",
            "Epoch 11/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 4.2536 - accuracy: 0.2031\n",
            "Epoch 12/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 4.1565 - accuracy: 0.2173\n",
            "Epoch 13/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 4.0686 - accuracy: 0.2265\n",
            "Epoch 14/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.9872 - accuracy: 0.2361\n",
            "Epoch 15/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.9135 - accuracy: 0.2453\n",
            "Epoch 16/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.8470 - accuracy: 0.2536\n",
            "Epoch 17/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.7787 - accuracy: 0.2644\n",
            "Epoch 18/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.7207 - accuracy: 0.2712\n",
            "Epoch 19/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.6598 - accuracy: 0.2798\n",
            "Epoch 20/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.6075 - accuracy: 0.2899\n",
            "Epoch 21/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.5561 - accuracy: 0.2960\n",
            "Epoch 22/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.5093 - accuracy: 0.3019\n",
            "Epoch 23/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.4643 - accuracy: 0.3088\n",
            "Epoch 24/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.4233 - accuracy: 0.3145\n",
            "Epoch 25/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.3815 - accuracy: 0.3198\n",
            "Epoch 26/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.3443 - accuracy: 0.3266\n",
            "Epoch 27/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.3077 - accuracy: 0.3330\n",
            "Epoch 28/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.2752 - accuracy: 0.3384\n",
            "Epoch 29/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.2427 - accuracy: 0.3429\n",
            "Epoch 30/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.2091 - accuracy: 0.3468\n",
            "Epoch 31/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.1800 - accuracy: 0.3532\n",
            "Epoch 32/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.1532 - accuracy: 0.3571\n",
            "Epoch 33/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.1254 - accuracy: 0.3606\n",
            "Epoch 34/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.0995 - accuracy: 0.3650\n",
            "Epoch 35/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.0703 - accuracy: 0.3697\n",
            "Epoch 36/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.0480 - accuracy: 0.3744\n",
            "Epoch 37/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.0270 - accuracy: 0.3782\n",
            "Epoch 38/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.9970 - accuracy: 0.3834\n",
            "Epoch 39/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.9761 - accuracy: 0.3855\n",
            "Epoch 40/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.9552 - accuracy: 0.3880\n",
            "Epoch 41/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.9360 - accuracy: 0.3925\n",
            "Epoch 42/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.9136 - accuracy: 0.3955\n",
            "Epoch 43/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.8881 - accuracy: 0.4013\n",
            "Epoch 44/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.8788 - accuracy: 0.4003\n",
            "Epoch 45/100\n",
            "1480/1480 [==============================] - 13s 8ms/step - loss: 2.8567 - accuracy: 0.4055\n",
            "Epoch 46/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.8372 - accuracy: 0.4096\n",
            "Epoch 47/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.8218 - accuracy: 0.4121\n",
            "Epoch 48/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.8009 - accuracy: 0.4148\n",
            "Epoch 49/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.7861 - accuracy: 0.4182\n",
            "Epoch 50/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.7681 - accuracy: 0.4191\n",
            "Epoch 51/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.7544 - accuracy: 0.4217\n",
            "Epoch 52/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.7335 - accuracy: 0.4246\n",
            "Epoch 53/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.7220 - accuracy: 0.4285\n",
            "Epoch 54/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.7181 - accuracy: 0.4282\n",
            "Epoch 55/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.6940 - accuracy: 0.4333\n",
            "Epoch 56/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.6734 - accuracy: 0.4353\n",
            "Epoch 57/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.6617 - accuracy: 0.4392\n",
            "Epoch 58/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.6537 - accuracy: 0.4401\n",
            "Epoch 59/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.6485 - accuracy: 0.4419\n",
            "Epoch 60/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.6246 - accuracy: 0.4444\n",
            "Epoch 61/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.6069 - accuracy: 0.4480\n",
            "Epoch 62/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.5999 - accuracy: 0.4477\n",
            "Epoch 63/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.5907 - accuracy: 0.4493\n",
            "Epoch 64/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.5857 - accuracy: 0.4518\n",
            "Epoch 65/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.5614 - accuracy: 0.4571\n",
            "Epoch 66/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.5570 - accuracy: 0.4567\n",
            "Epoch 67/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.5437 - accuracy: 0.4578\n",
            "Epoch 68/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.5313 - accuracy: 0.4611\n",
            "Epoch 69/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.5166 - accuracy: 0.4631\n",
            "Epoch 70/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.5144 - accuracy: 0.4648\n",
            "Epoch 71/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.5041 - accuracy: 0.4682\n",
            "Epoch 72/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4880 - accuracy: 0.4701\n",
            "Epoch 73/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4774 - accuracy: 0.4719\n",
            "Epoch 74/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4716 - accuracy: 0.4713\n",
            "Epoch 75/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4735 - accuracy: 0.4713\n",
            "Epoch 76/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4564 - accuracy: 0.4728\n",
            "Epoch 77/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4460 - accuracy: 0.4754\n",
            "Epoch 78/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4410 - accuracy: 0.4780\n",
            "Epoch 79/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4272 - accuracy: 0.4801\n",
            "Epoch 80/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4122 - accuracy: 0.4825\n",
            "Epoch 81/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4074 - accuracy: 0.4833\n",
            "Epoch 82/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4073 - accuracy: 0.4841\n",
            "Epoch 83/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3929 - accuracy: 0.4854\n",
            "Epoch 84/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3748 - accuracy: 0.4894\n",
            "Epoch 85/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3762 - accuracy: 0.4877\n",
            "Epoch 86/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3671 - accuracy: 0.4920\n",
            "Epoch 87/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3620 - accuracy: 0.4920\n",
            "Epoch 88/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3499 - accuracy: 0.4937\n",
            "Epoch 89/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3501 - accuracy: 0.4938\n",
            "Epoch 90/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3376 - accuracy: 0.4963\n",
            "Epoch 91/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3346 - accuracy: 0.4979\n",
            "Epoch 92/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3406 - accuracy: 0.4949\n",
            "Epoch 93/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3129 - accuracy: 0.5018\n",
            "Epoch 94/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3100 - accuracy: 0.5003\n",
            "Epoch 95/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3054 - accuracy: 0.5016\n",
            "Epoch 96/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.3029 - accuracy: 0.5035\n",
            "Epoch 97/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.3078 - accuracy: 0.5028\n",
            "Epoch 98/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.2858 - accuracy: 0.5062\n",
            "Epoch 99/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.2939 - accuracy: 0.5049\n",
            "Epoch 100/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.2819 - accuracy: 0.5066\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Q8ZrfI3CH-V",
        "colab_type": "text"
      },
      "source": [
        "# View The Training Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deLHU6HmCHUa",
        "colab_type": "code",
        "outputId": "d51f2418-8e18-455a-b540-0de65ae674e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()\n",
        "\n",
        "plot_graphs(history, 'accuracy')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bsrN8L9CSd5",
        "colab_type": "text"
      },
      "source": [
        "# Generate Better Lyrics!\n",
        "This time around, we should be able to get a more interesting output with less repetition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkHQXFquCTEX",
        "colab_type": "code",
        "outputId": "f46d14ed-938c-4419-9135-6c0dfdc71846",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "im feeling chills me to the farm with a movie star the morning goes down honey rainy bless you die win slack cryin twist twist twist twist twist son gain kissed beat posses famous twist twist twist son wish wish buddy girlya forgot foolish clothes somebodys tone pain understand heal to whom to jive depressed to go down there and holding once me light me yonder get it thru so hard upon ya dream is a merry lover beat looking for your other side of your heart choice diamond games seventeen distant wish urge apple held the pirouette gain above clothes messin awaited\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdURbkRWJzXY",
        "colab_type": "text"
      },
      "source": [
        "# Varying The Possible Outputs\n",
        "In running the above, you may notice that the same seed text will generate similar outputs. This is because the code is currently always choosing the top predicted class as the next word. What if you wanted more variance in the output?\n",
        "\n",
        "Switching from model.predict_classes to model.predict_proba will get us all of the class probabilities. We can combine this with np.random.choice to select a given predicted output based on a probability, thereby giving a bit more randomness to our outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75wn0MrsJz4W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17cea87a-ec9a-4d36-c997-2a5ec60b0a6e"
      },
      "source": [
        "# Test the method with just the first word after the seed text\n",
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "predicted_probs = model.predict(token_list)[0]\n",
        "predicted = np.random.choice([x for x in range(len(predicted_probs))], \n",
        "                             p=predicted_probs)\n",
        "# Running this cell multiple times should get you some variance in output\n",
        "print(predicted)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSdwbIyOK8GR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e928b12d-33be-4989-f8fc-20ef18990b61"
      },
      "source": [
        "# Use this process for the full output generation\n",
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "  token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "  predicted_probs = model.predict(token_list)[0]\n",
        "  predicted = np.random.choice([x for x in range(len(predicted_probs))],\n",
        "                               p=predicted_probs)\n",
        "  output_word = \"\"\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == predicted:\n",
        "      output_word = word\n",
        "      break\n",
        "  seed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "im feeling chills me it aint fair high why wrong in the lips very sunny first side smile money way know when his through the ground of rock of sucker tongue roll held beat trip arbuckle feeds pack pack win winner toys winner laid mornin fernando fernando today down me my happiest visitors going to me go low down through trial full circle colors above me he mean they come home sit shining his dust away let my smile for me to my angel whos going movin on me to control go away he mighty disguise just how nothing has how depressed we\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjS08n9uM25E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}